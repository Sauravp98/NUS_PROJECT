{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.learning_curve import learning_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"new1.csv\")\n",
    "\n",
    "l1=(\"Adventure\",\"Comedy\",\"Action\",\"Drama\",\"Crime\",\"Thriller\",\"Horror\",\"Animation\",\"Biography\",\"Sci-Fi\",\"Musical\",\"Family\",\"Fantasy\",\"Mystery\",\"War\",\"Romance\",\"Western\")\n",
    "l2=(\"Argentina\",\"Australia\",\"Belgium\",\"Canada\",\"Chile\",\"Czech Republic\",\"Ireland\",\"Panama\",\"China\",\"Denmark\",\"France\",\"Germany\",\"Hong Kong\",\"Hungary\",\"Iran\",\"Isreal\",\"Italy\",\"Japan\",\"Netherlands\",\"New Zealand\",\"Peru\",\"South Africa\",\"Spain\",\"Sweden\",\"Switzerland\",\"UK\",\"USA\",\"West Germany\")\n",
    "l3=(\"R\",\"PG-13\",\"PG\",\"UNRATED\",\"G\",\"NC-17\",\"TV-PG\",\"TV-MA\",\"B\",\"B15\",\"TV-14\")\n",
    "\n",
    "def score_to_numeric1(x):\n",
    "    for j in range(len(l1)):\n",
    "         if(x==l1[j]):\n",
    "            return j\n",
    "        \n",
    "def score_to_numeric2(x):\n",
    "    for j in range(len(l2)):\n",
    "         if(x==l2[j]):\n",
    "            return j  \n",
    "        \n",
    "def score_to_numeric3(x):\n",
    "    for j in range(len(l3)):\n",
    "         if(x==l3[j]):\n",
    "            return j\n",
    "         else:\n",
    "            return 3\n",
    "        \n",
    "data['genre'] = data['genre'].apply(score_to_numeric1)\n",
    "data['country'] = data['country'].apply(score_to_numeric2)\n",
    "data['rating'] = data['rating'].apply(score_to_numeric3)\n",
    "\n",
    "data = data[np.isfinite(data['genre'])]\n",
    "data = data[np.isfinite(data['country'])]\n",
    "data = data[np.isfinite(data['rating'])]\n",
    "\n",
    "X = data.drop(['gross','company','director','name','released','star','writer'],axis=1)\n",
    "\n",
    "Y=data['gross']       \n",
    "Y = Y.values#.reshape(-1, 1)##convert 1 col to 2d matrix with replace\n",
    "\n",
    "for i in range(Y.size):\n",
    "    if(Y[i]<30000000.00):\n",
    "        Y[i]=1\n",
    "    else:\n",
    "        Y[i]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5332, 10) (5332,)\n",
      "(1334, 10) (1334,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, shuffle=True)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
      "          solver='warn', tol=0.0001, verbose=0, warm_start=False)\n",
      "Coefficients =  [[-1.29231803e-04  4.36507809e-08 -1.05714085e-05 -1.74369074e-06\n",
      "   6.87761501e-08 -6.10670042e-05 -3.81756780e-06  1.35311166e-05\n",
      "  -1.13339363e-03 -3.52981175e-06]]\n",
      "Intercept =  [-5.7062613e-07]\n",
      "Training Accuracy 0.8387096774193549\n",
      "Training Confusion = [[3366  652]\n",
      " [ 208 1106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.94      0.89      3574\n",
      "           2       0.84      0.63      0.72      1758\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      5332\n",
      "   macro avg       0.84      0.79      0.80      5332\n",
      "weighted avg       0.84      0.84      0.83      5332\n",
      "\n",
      "========================================================\n",
      "Test Accuracy 0.8298350824587706\n",
      "Test Confusion = [[844 158]\n",
      " [ 69 263]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.92      0.88       913\n",
      "           2       0.79      0.62      0.70       421\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1334\n",
      "   macro avg       0.82      0.77      0.79      1334\n",
      "weighted avg       0.83      0.83      0.82      1334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Swayamprava/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['lrweight.joblib']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##LOGISTIC REGRESSION MODEL\n",
    "lr = LogisticRegression(C=1e5)\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred_train = lr.predict(x_train)\n",
    "y_pred_test = lr.predict(x_test)\n",
    "\n",
    "print(lr)\n",
    "print('Coefficients = ', lr.coef_)\n",
    "print('Intercept = ', lr.intercept_)\n",
    "\n",
    "print('Training Accuracy {}'.format(lr.score(x_train, y_train)))\n",
    "print('Training Confusion = {}'.format(metrics.confusion_matrix(y_pred_train, y_train)))\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print('========================================================')\n",
    "print('Test Accuracy {}'.format(lr.score(x_test, y_test)))\n",
    "print('Test Confusion = {}'.format(metrics.confusion_matrix(y_pred_test, y_test)))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "#saving the weights\n",
    "joblib.dump(lr,'lrweight.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Training Accuracy 1.0\n",
      "Training Confusion = [[   0    0    0]\n",
      " [   0 3574    0]\n",
      " [   0    0 1758]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      3574\n",
      "           2       1.00      1.00      1.00      1758\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      5332\n",
      "   macro avg       1.00      1.00      1.00      5332\n",
      "weighted avg       1.00      1.00      1.00      5332\n",
      "\n",
      "========================================================\n",
      "Test Accuracy 0.8013493253373314\n",
      "Test Confusion = [[  0   0   0]\n",
      " [  0 768 120]\n",
      " [  0 145 301]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.84      0.85       913\n",
      "           2       0.67      0.71      0.69       421\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1334\n",
      "   macro avg       0.77      0.78      0.77      1334\n",
      "weighted avg       0.80      0.80      0.80      1334\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['dtweight.joblib']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##DECISION TREE MODEL\n",
    "clfdt = tree.DecisionTreeClassifier(criterion='gini', splitter='best')\n",
    "clfdt.fit(x_train, y_train)\n",
    "y_pred_train = clfdt.predict(x_train)\n",
    "y_pred_test = clfdt.predict(x_test)\n",
    "print(clfdt)\n",
    "\n",
    "#dot_data = tree.export_graphviz(clfdt, out_file=None, feature_names=['sepal_length','sepal_width','petal_length','petal_width'],class_names=['setosa','versicolor','virginica'], filled=True, rounded=True, special_characters=True)\n",
    "#graph = graphviz.Source(dot_data)\n",
    "#graph.render(\"movie-train\")\n",
    "print('Training Accuracy {}'.format(clfdt.score(x_train, y_train)))\n",
    "print('Training Confusion = {}'.format(metrics.confusion_matrix(y_pred_train, y_train, [0,1,2])))\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print('========================================================')\n",
    "print('Test Accuracy {}'.format(clfdt.score(x_test, y_test)))\n",
    "print('Test Confusion = {}'.format(metrics.confusion_matrix(y_pred_test, y_test, [0,1,2])))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "#saving the weights\n",
    "joblib.dump(clfdt,'dtweight.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "Training Accuracy 0.7258064516129032\n",
      "Training Confusion = [[   0    0    0]\n",
      " [   0 3570 1458]\n",
      " [   0    4  300]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      1.00      0.83      3574\n",
      "           2       0.99      0.17      0.29      1758\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      5332\n",
      "   macro avg       0.85      0.58      0.56      5332\n",
      "weighted avg       0.80      0.73      0.65      5332\n",
      "\n",
      "========================================================\n",
      "Test Accuracy 0.7331334332833583\n",
      "Test Confusion = [[  0   0   0]\n",
      " [  0 912 355]\n",
      " [  0   1  66]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      1.00      0.84       913\n",
      "           2       0.99      0.16      0.27       421\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      1334\n",
      "   macro avg       0.85      0.58      0.55      1334\n",
      "weighted avg       0.80      0.73      0.66      1334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Swayamprava/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['svcwt.joblib']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##SUPPORT VECTOR MACHINE MODEL\n",
    "svc = LinearSVC()\n",
    "svc.fit(x_train, y_train)\n",
    "y_pred_train = svc.predict(x_train)\n",
    "y_pred_test = svc.predict(x_test)\n",
    "\n",
    "print(svc)\n",
    "\n",
    "print('Training Accuracy {}'.format(svc.score(x_train, y_train)))\n",
    "print('Training Confusion = {}'.format(metrics.confusion_matrix(y_pred_train, y_train, [0,1,2])))\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print('========================================================')\n",
    "print('Test Accuracy {}'.format(svc.score(x_test, y_test)))\n",
    "print('Test Confusion = {}'.format(metrics.confusion_matrix(y_pred_test, y_test, [0,1,2])))\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "#saving the weights\n",
    "joblib.dump(svc,'svcwt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
      "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
      "       validation_fraction=0.1, verbose=False, warm_start=False)\n",
      "Training Accuracy 0.5395723930982745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.37      0.53      3770\n",
      "           2       0.38      0.95      0.55      1562\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      5332\n",
      "   macro avg       0.67      0.66      0.54      5332\n",
      "weighted avg       0.78      0.54      0.54      5332\n",
      "\n",
      "Test Accuracy 0.7758620689655172\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nnwt.joblib']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##NEURAL NETWORK MODEL\n",
    "NN=MLPClassifier().fit(x_train,y_train)\n",
    "#hidden_layer_sizes=(4,3), activation='relu',solver='adam',alpha=0.001\n",
    "y_pred_train = NN.predict(x_train)\n",
    "y_pred_test = NN.predict(x_test)\n",
    "print(NN)\n",
    "print('Training Accuracy {}'.format(NN.score(x_train, y_train)))\n",
    "print(classification_report(y_train, y_pred_train))\n",
    "print('Test Accuracy {}'.format(svc.score(x_test, y_test)))\n",
    "#saving the weights\n",
    "joblib.dump(NN,'nnwt.joblib')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ACCURACY 0.9714928732183046\n",
      "TEST ACCURACY 0.8673163418290855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rfwt.joblib']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##RANDOMFORREST CLASSIFIER\n",
    "rf = RandomForestClassifier(max_depth=10, n_estimators=20, max_features=10,criterion='gini').fit(x_train,y_train)\n",
    "print(\"TRAIN ACCURACY\",rf.score(x_train,y_train))\n",
    "print(\"TEST ACCURACY\",rf.score(x_test,y_test))\n",
    "#print(accuracy_score(y_train, , normalize=True, sample_weight=None))\n",
    "joblib.dump(rf,'rfwt.joblib')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ACCURACY 0.8805326331582896\n",
      "TEST ACCURACY 0.8268365817091454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['knnwt.joblib']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#K-nearest neighbours\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train,y_train) \n",
    "print(\"TRAIN ACCURACY\",knn.score(x_train,y_train))\n",
    "print(\"TEST ACCURACY\",knn.score(x_test,y_test))\n",
    "#print(accuracy_score(y_train, , normalize=True, sample_weight=None))\n",
    "joblib.dump(rf,'knnwt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ACCURACY 1.0\n",
      "TEST ACCURACY 0.8605697151424287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Swayamprava/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['extwt.joblib']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extratree classifier\n",
    "ext=ExtraTreesClassifier(criterion='gini')\n",
    "ext.fit(x_train,y_train) \n",
    "print(\"TRAIN ACCURACY\",ext.score(x_train,y_train))\n",
    "print(\"TEST ACCURACY\",ext.score(x_test,y_test))\n",
    "#print(accuracy_score(y_train, , normalize=True, sample_weight=None))\n",
    "joblib.dump(ext,'extwt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN ACCURACY 1.0\n",
      "TEST ACCURACY 0.8605697151424287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['nbcwt.joblib']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes Classifier\n",
    "nbc=GaussianNB()\n",
    "nbc.fit(x_train,y_train) \n",
    "print(\"TRAIN ACCURACY\",ext.score(x_train,y_train))\n",
    "print(\"TEST ACCURACY\",ext.score(x_test,y_test))\n",
    "#print(accuracy_score(y_train, , normalize=True, sample_weight=None))\n",
    "joblib.dump(nbc,'nbcwt.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
